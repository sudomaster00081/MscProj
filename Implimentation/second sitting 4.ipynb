{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7cf4c6-b23f-42a4-a7e0-522e8f9f1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from minisom import MiniSom\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"labeled_ddostrace.to-victim.20070804.csv\")\n",
    "\n",
    "# Convert other columns to appropriate data types\n",
    "data['Source IP'] = data['Source IP'].astype(str)\n",
    "data['Destination IP'] = data['Destination IP'].astype(str)\n",
    "data['Protocol'] = pd.to_numeric(data['Protocol'], errors='coerce') # if it's numeric\n",
    "data['Frame Length'] = pd.to_numeric(data['Frame Length'], errors='coerce') # if it's numeric\n",
    "data['Port Used'] = pd.to_numeric(data['Port Used'], errors='coerce') # if it's numeric\n",
    "data['Interpacket Time'] = pd.to_numeric(data['Interpacket Time'], errors='coerce') # if it's numeric\n",
    "data['Entropy'] = pd.to_numeric(data['Entropy'], errors='coerce') # if it's numeric\n",
    "data['label'] = pd.to_numeric(data['label'], errors='coerce') # if it's numeric\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(['label', 'Timestamp', 'Source IP', 'Destination IP'], axis=1).values\n",
    "y = data['label'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define SOM parameters\n",
    "som_grid_rows = 10\n",
    "som_grid_columns = 10\n",
    "input_len = X_scaled.shape[1]\n",
    "num_iterations = 10000\n",
    "\n",
    "# Train SOM incrementally\n",
    "som = MiniSom(som_grid_rows, som_grid_columns, input_len, sigma=1.0, learning_rate=0.5)\n",
    "som.random_weights_init(X_scaled)\n",
    "\n",
    "def train_som_iteration(X):\n",
    "    som.train_random(X, 1)\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(train_som_iteration)(X_scaled) for _ in range(num_iterations))\n",
    "\n",
    "# Find the winning neurons for each sample\n",
    "winning_neurons = np.array([som.winner(x) for x in X_scaled])\n",
    "\n",
    "# Assign labels to clusters based on the majority label of the samples in each cluster\n",
    "cluster_labels = []\n",
    "total_samples = len(winning_neurons)\n",
    "\n",
    "def assign_cluster_label(neuron):\n",
    "    cluster_samples_indices = np.where((winning_neurons[:, 0] == neuron[0]) & (winning_neurons[:, 1] == neuron[1]))[0]\n",
    "    return y[cluster_samples_indices].mean()\n",
    "\n",
    "cluster_labels = Parallel(n_jobs=-1)(delayed(assign_cluster_label)(neuron) for neuron in winning_neurons)\n",
    "\n",
    "# Print progress\n",
    "print(\"Assigning cluster labels: 100.00% complete\")\n",
    "\n",
    "# Convert labels to binary (assuming 0 for non-DDoS and 1 for DDoS)\n",
    "y_binary = np.where(y > 0, 1, 0)\n",
    "\n",
    "# Convert cluster labels to binary\n",
    "cluster_labels_binary = np.where(np.array(cluster_labels) > 0, 1, 0)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_binary, cluster_labels_binary)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a56d8f2-e442-40a0-8a7b-1717ee576009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21148\\4100079094.py:5: DtypeWarning: Columns (0,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('labeled_ddostrace.to-victim.20070804.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of Source IP addresses: 8.633429095354296\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV data into a DataFrame\n",
    "df = pd.read_csv('labeled_ddostrace.to-victim.20070804.csv')\n",
    "\n",
    "# Calculate probabilities of each unique value\n",
    "unique_values = df['Source IP'].unique()\n",
    "probabilities = df['Source IP'].value_counts(normalize=True)\n",
    "\n",
    "# Calculate entropy\n",
    "entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "print(\"Entropy of Source IP addresses:\", entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2108d1b5-0ce6-445b-b119-b8d0f0891646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of packets: 1134552\n"
     ]
    }
   ],
   "source": [
    "total_packets = len(df)\n",
    "print(\"Total number of packets:\", total_packets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5464e549-fb21-4292-849a-ac2c1afee4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate entropy\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "# Calculate entropy for each feature\n",
    "source_ip_probabilities = df['Source IP'].value_counts(normalize=True)\n",
    "source_port_probabilities = df['Port Used'].value_counts(normalize=True)\n",
    "dest_port_probabilities = df['Port Used'].value_counts(normalize=True)\n",
    "protocol_probabilities = df['Protocol'].value_counts(normalize=True)\n",
    "\n",
    "source_ip_entropy = calculate_entropy(source_ip_probabilities)\n",
    "source_port_entropy = calculate_entropy(source_port_probabilities)\n",
    "dest_port_entropy = calculate_entropy(dest_port_probabilities)\n",
    "protocol_entropy = calculate_entropy(protocol_probabilities)\n",
    "\n",
    "total_packets = len(df)\n",
    "\n",
    "# Add the calculated entropy values as new columns\n",
    "df['Entropy of Source IP'] = source_ip_entropy\n",
    "df['Entropy of Source Port'] = source_port_entropy\n",
    "df['Entropy of Destination Port'] = dest_port_entropy\n",
    "df['Entropy of Protocol'] = protocol_entropy\n",
    "df['Total Packets'] = total_packets\n",
    "\n",
    "# Save the modified DataFrame with new features\n",
    "df.to_csv('modified_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9604956-9d66-4866-bf76-a343d166459c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
