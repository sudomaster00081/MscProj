{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d3a77-a50e-4726-a70a-d5fc211629d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20712\\4155266547.py:8: DtypeWarning: Columns (0,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"labeled_ddostrace.to-victim.20070804.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 0 1]\n",
      "Assigning cluster labels: 0.09% complete\n",
      "Assigning cluster labels: 0.18% complete\n",
      "Assigning cluster labels: 0.26% complete\n",
      "Assigning cluster labels: 0.35% complete\n",
      "Assigning cluster labels: 0.44% complete\n",
      "Assigning cluster labels: 0.53% complete\n",
      "Assigning cluster labels: 0.62% complete\n",
      "Assigning cluster labels: 0.71% complete\n",
      "Assigning cluster labels: 0.79% complete\n",
      "Assigning cluster labels: 0.88% complete\n",
      "Assigning cluster labels: 0.97% complete\n",
      "Assigning cluster labels: 1.06% complete\n",
      "Assigning cluster labels: 1.15% complete\n",
      "Assigning cluster labels: 1.23% complete\n",
      "Assigning cluster labels: 1.32% complete\n",
      "Assigning cluster labels: 1.41% complete\n",
      "Assigning cluster labels: 1.50% complete\n",
      "Assigning cluster labels: 1.59% complete\n",
      "Assigning cluster labels: 1.67% complete\n",
      "Assigning cluster labels: 1.76% complete\n",
      "Assigning cluster labels: 1.85% complete\n",
      "Assigning cluster labels: 1.94% complete\n",
      "Assigning cluster labels: 2.03% complete\n",
      "Assigning cluster labels: 2.12% complete\n",
      "Assigning cluster labels: 2.20% complete\n",
      "Assigning cluster labels: 2.29% complete\n",
      "Assigning cluster labels: 2.38% complete\n",
      "Assigning cluster labels: 2.47% complete\n",
      "Assigning cluster labels: 2.56% complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from minisom import MiniSom\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"labeled_ddostrace.to-victim.20070804.csv\")\n",
    "\n",
    "# Convert other columns to appropriate data types\n",
    "data['Source IP'] = data['Source IP'].astype(str)\n",
    "data['Destination IP'] = data['Destination IP'].astype(str)\n",
    "data['Protocol'] = pd.to_numeric(data['Protocol'], errors='coerce') # if it's numeric\n",
    "data['Frame Length'] = pd.to_numeric(data['Frame Length'], errors='coerce') # if it's numeric\n",
    "data['Port Used'] = pd.to_numeric(data['Port Used'], errors='coerce') # if it's numeric\n",
    "data['Interpacket Time'] = pd.to_numeric(data['Interpacket Time'], errors='coerce') # if it's numeric\n",
    "data['Entropy'] = pd.to_numeric(data['Entropy'], errors='coerce') # if it's numeric\n",
    "data['label'] = pd.to_numeric(data['label'], errors='coerce') # if it's numeric\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(['label', 'Timestamp', 'Source IP', 'Destination IP'], axis=1).values\n",
    "y = data['label'].values\n",
    "print(y)\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define SOM parameters\n",
    "som_grid_rows = 10\n",
    "som_grid_columns = 10\n",
    "input_len = X_scaled.shape[1]\n",
    "num_iterations = 10000\n",
    "\n",
    "# Train SOM\n",
    "som = MiniSom(som_grid_rows, som_grid_columns, input_len, sigma=1.0, learning_rate=0.5)\n",
    "som.random_weights_init(X_scaled)\n",
    "som.train_batch(X_scaled, num_iterations)\n",
    "\n",
    "# Find the winning neurons for each sample\n",
    "winning_neurons = np.array([som.winner(x) for x in X_scaled])\n",
    "\n",
    "# Assign labels to clusters based on the majority label of the samples in each cluster\n",
    "cluster_labels = []\n",
    "total_samples = len(winning_neurons)\n",
    "\n",
    "for i, neuron in enumerate(winning_neurons):\n",
    "    cluster_samples_indices = np.where((winning_neurons[:, 0] == neuron[0]) & (winning_neurons[:, 1] == neuron[1]))[0]\n",
    "    cluster_labels.append(y[cluster_samples_indices].mean())\n",
    "\n",
    "    # Print progress\n",
    "    if (i + 1) % 1000 == 0 or i + 1 == total_samples:\n",
    "        percent_complete = (i + 1) / total_samples * 100\n",
    "        print(f\"Assigning cluster labels: {percent_complete:.2f}% complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c50b60-783c-4c21-a620-84323ee35708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to binary (assuming 0 for non-DDoS and 1 for DDoS)\n",
    "y_binary = np.where(y > 0, 1, 0)\n",
    "# print(y_binary)\n",
    "# print(cluster_labels)\n",
    "# Convert cluster labels to binary\n",
    "cluster_labels_binary = np.where(np.array(cluster_labels) > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed14b4-ec6a-4f45-8055-33f2fd8499e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_binary, cluster_labels_binary)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7cbff0-8e56-4970-89c3-57fc17f3b5a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate accuracy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[1;32m~\\Envs\\msc\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\Envs\\msc\\lib\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\Envs\\msc\\lib\\site-packages\\sklearn\\metrics\\_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     96\u001b[0m             type_true, type_pred\n\u001b[0;32m     97\u001b[0m         )\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# # Evaluate accuracy\n",
    "# accuracy = accuracy_score(y, cluster_labels)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bfab3-cd4d-4ce7-b7c2-0fde06258573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85e887-80ed-4b56-830e-062935ca7b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
